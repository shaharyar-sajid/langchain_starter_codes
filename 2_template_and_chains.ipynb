{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3d92f5",
   "metadata": {},
   "source": [
    "# Templates, chains and multi-chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6658d92a",
   "metadata": {},
   "source": [
    "This example cover a few different topics:\n",
    "- How to use LangChain Expression Language (LCEL) to build simple text generation chains.\n",
    "- Create prompt templates, connects them to an OpenAI chat model (gpt-5-nano), and parse the modelâ€™s output into plain text.\n",
    "- Use multi-chaining where one chains output is fed into another chain. In this notebook, a function is generated from the first chain and the second chain generates its test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebc7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4beced6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c855965",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1740e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a very short {language} function that will {task}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ce99304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is LCEL (LangChain Expression Language). Langchains new method of chaining.\n",
    "chain = code_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed9dbbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\n",
    "    \"language\": \"python\",\n",
    "    \"task\": \"return a list of numbers\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def numbers(n): return list(range(n))\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf4daa",
   "metadata": {},
   "source": [
    "## Multi-chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "181ead06",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a very short {language} function that will {task}.\"\n",
    ")\n",
    "\n",
    "test_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write test code for the following {language} code:\\n{code}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f45434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_chain = code_prompt | llm | StrOutputParser()\n",
    "test_chain = test_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d74e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_result = code_chain.invoke({\"task\": \"return a list of numbers\", \"language\": \"Python\"})\n",
    "test_result = test_chain.invoke({\"language\": \"Python\", \"code\": code_result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945de480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>> GENERATED CODE:\n",
      "def nums():\n",
      "    return [1, 2, 3, 4, 5]\n",
      ">>>>>> GENERATED TEST:\n",
      "Here are two common test approaches. Replace your_module with the actual module name that defines nums.\n",
      "\n",
      "Option 1: pytest\n",
      "\n",
      "# tests/test_nums.py\n",
      "from your_module import nums  # replace with the actual module name\n",
      "\n",
      "def test_nums_returns_expected_list():\n",
      "    assert nums() == [1, 2, 3, 4, 5]\n",
      "\n",
      "def test_nums_list_integrity():\n",
      "    res = nums()\n",
      "    assert isinstance(res, list)\n",
      "    assert len(res) == 5\n",
      "    assert all(isinstance(x, int) for x in res)\n",
      "\n",
      "def test_nums_new_list_each_call():\n",
      "    a = nums()\n",
      "    b = nums()\n",
      "    assert a == b\n",
      "    assert a is not b\n",
      "\n",
      "Option 2: unittest\n",
      "\n",
      "# tests/test_nums.py\n",
      "import unittest\n",
      "from your_module import nums  # replace with the actual module name\n",
      "\n",
      "class TestNums(unittest.TestCase):\n",
      "    def test_basic(self):\n",
      "        self.assertEqual(nums(), [1, 2, 3, 4, 5])\n",
      "\n",
      "    def test_types_and_length(self):\n",
      "        res = nums()\n",
      "        self.assertIsInstance(res, list)\n",
      "        self.assertEqual(len(res), 5)\n",
      "        self.assertTrue(all(isinstance(i, int) for i in res))\n",
      "\n",
      "    def test_new_list_each_call(self):\n",
      "        a = nums()\n",
      "        b = nums()\n",
      "        self.assertEqual(a, b)\n",
      "        self.assertIsNot(a, b)\n",
      "\n",
      "If you run pytest, simply place the pytest version in a tests/ directory and run pytest. For unittest, run the file directly or via a test runner.\n"
     ]
    }
   ],
   "source": [
    "print(\">>>>>> GENERATED CODE:\")\n",
    "print(code_result)\n",
    "print(\">>>>>> GENERATED TEST:\")\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fda2522",
   "metadata": {},
   "source": [
    "# Older way of doing chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ab942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea68f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\"\n",
    "\n",
    "llm = OpenAI(\n",
    "    openai_api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d4188",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_prompt = PromptTemplate(\n",
    "    template=\"Write a very short {language} function that will {task}\",\n",
    "    input_variables=[\"language\", \"task\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a558d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=code_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = code_chain({\n",
    "    \"language\": \"python\",\n",
    "    \"task\": \"return a list of numbers\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c80fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c52696",
   "metadata": {},
   "source": [
    "## Multi Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\", \"language\"],\n",
    "    template=\"Write a very short {language} function that will {task}.\"\n",
    ")\n",
    "test_prompt = PromptTemplate(\n",
    "    input_variables=[\"language\", \"code\"],\n",
    "    template=\"Write test code for the following {language} code:\\n{code}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5734cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=code_prompt,\n",
    "    output_key=\"code\"\n",
    ")\n",
    "test_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=test_prompt,\n",
    "    output_key=\"test\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c66647",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SequentialChain(\n",
    "    chains=[code_chain, test_chain],\n",
    "    input_variables=[\"task\", \"language\"],\n",
    "    output_variables=[\"test\", \"code\"]\n",
    ")\n",
    "result = chain({\n",
    "    \"language\": \"Python\",\n",
    "    \"task\": \"return a list of numbers\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe711d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>>>>> GENERATED CODE:\")\n",
    "print(result[\"code\"])\n",
    "print(\">>>>>> GENERATED TEST:\")\n",
    "print(result[\"test\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
